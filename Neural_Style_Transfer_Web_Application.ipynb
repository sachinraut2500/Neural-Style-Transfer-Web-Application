{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zDQx5bJosNl_",
        "outputId": "8a9a3077-fe59-451f-bfab-eea8a5f81bbe"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "ðŸŽ¨ Neural Style Transfer Web App Starting...\n",
            "ðŸ“± Access the app at: http://localhost:5000\n",
            "ðŸ”§ API endpoint: http://localhost:5000/transfer\n",
            " * Serving Flask app '__main__'\n",
            " * Debug mode: on\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:werkzeug:\u001b[31m\u001b[1mWARNING: This is a development server. Do not use it in a production deployment. Use a production WSGI server instead.\u001b[0m\n",
            " * Running on all addresses (0.0.0.0)\n",
            " * Running on http://127.0.0.1:5000\n",
            " * Running on http://172.28.0.12:5000\n",
            "INFO:werkzeug:\u001b[33mPress CTRL+C to quit\u001b[0m\n",
            "INFO:werkzeug: * Restarting with stat\n"
          ]
        }
      ],
      "source": [
        "# Neural Style Transfer Web Application\n",
        "# File: neural_style_transfer_webapp.py\n",
        "\n",
        "import os\n",
        "import numpy as np\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras.applications import VGG19\n",
        "from tensorflow.keras.preprocessing.image import load_img, img_to_array\n",
        "import matplotlib.pyplot as plt\n",
        "from flask import Flask, request, jsonify, render_template_string\n",
        "import base64\n",
        "import io\n",
        "from PIL import Image\n",
        "import logging\n",
        "\n",
        "# Configure logging\n",
        "logging.basicConfig(level=logging.INFO)\n",
        "logger = logging.getLogger(__name__)\n",
        "\n",
        "class NeuralStyleTransfer:\n",
        "    def __init__(self, content_layers=['block5_conv2'],\n",
        "                 style_layers=['block1_conv1', 'block2_conv1', 'block3_conv1', 'block4_conv1', 'block5_conv1']):\n",
        "        \"\"\"\n",
        "        Initialize Neural Style Transfer model\n",
        "\n",
        "        Args:\n",
        "            content_layers: Layers to extract content features\n",
        "            style_layers: Layers to extract style features\n",
        "        \"\"\"\n",
        "        self.content_layers = content_layers\n",
        "        self.style_layers = style_layers\n",
        "        self.num_content_layers = len(content_layers)\n",
        "        self.num_style_layers = len(style_layers)\n",
        "\n",
        "        # Build the VGG model\n",
        "        self.vgg = self.vgg_layers(self.style_layers + self.content_layers)\n",
        "        self.vgg.trainable = False\n",
        "\n",
        "        # Style and content weights\n",
        "        self.style_weight = 1e-2\n",
        "        self.content_weight = 1e4\n",
        "        self.total_variation_weight = 30\n",
        "\n",
        "    def vgg_layers(self, layer_names):\n",
        "        \"\"\"Create a VGG model that returns feature maps for specified layers\"\"\"\n",
        "        vgg = VGG19(include_top=False, weights='imagenet')\n",
        "        vgg.trainable = False\n",
        "\n",
        "        outputs = [vgg.get_layer(name).output for name in layer_names]\n",
        "        model = tf.keras.Model([vgg.input], outputs)\n",
        "        return model\n",
        "\n",
        "    def preprocess_image(self, image_path, max_dim=512):\n",
        "        \"\"\"Load and preprocess image\"\"\"\n",
        "        img = load_img(image_path)\n",
        "        img = tf.image.convert_image_dtype(img, tf.float32)\n",
        "\n",
        "        shape = tf.cast(tf.shape(img)[:-1], tf.float32)\n",
        "        long_dim = max(shape)\n",
        "        scale = max_dim / long_dim\n",
        "\n",
        "        new_shape = tf.cast(shape * scale, tf.int32)\n",
        "        img = tf.image.resize(img, new_shape)\n",
        "        img = img[tf.newaxis, :]\n",
        "        return img\n",
        "\n",
        "    def deprocess_image(self, processed_img):\n",
        "        \"\"\"Convert processed image back to displayable format\"\"\"\n",
        "        x = processed_img.copy()\n",
        "        if len(x.shape) == 4:\n",
        "            x = np.squeeze(x, 0)\n",
        "\n",
        "        # Remove zero-center by mean pixel\n",
        "        x[:, :, 0] += 103.939\n",
        "        x[:, :, 1] += 116.779\n",
        "        x[:, :, 2] += 123.68\n",
        "\n",
        "        # Convert BGR to RGB\n",
        "        x = x[:, :, ::-1]\n",
        "        x = np.clip(x, 0, 255).astype('uint8')\n",
        "        return x\n",
        "\n",
        "    def gram_matrix(self, input_tensor):\n",
        "        \"\"\"Calculate Gram matrix for style representation\"\"\"\n",
        "        result = tf.linalg.einsum('bijc,bijd->bcd', input_tensor, input_tensor)\n",
        "        input_shape = tf.shape(input_tensor)\n",
        "        num_locations = tf.cast(input_shape[1]*input_shape[2], tf.float32)\n",
        "        return result/(num_locations)\n",
        "\n",
        "    def style_content_loss(self, outputs, style_targets, content_targets):\n",
        "        \"\"\"Calculate style and content loss\"\"\"\n",
        "        style_outputs = outputs['style']\n",
        "        content_outputs = outputs['content']\n",
        "\n",
        "        style_loss = tf.add_n([tf.reduce_mean((style_outputs[name]-style_targets[name])**2)\n",
        "                               for name in style_outputs.keys()])\n",
        "        style_loss *= self.style_weight / self.num_style_layers\n",
        "\n",
        "        content_loss = tf.add_n([tf.reduce_mean((content_outputs[name]-content_targets[name])**2)\n",
        "                                 for name in content_outputs.keys()])\n",
        "        content_loss *= self.content_weight / self.num_content_layers\n",
        "\n",
        "        loss = style_loss + content_loss\n",
        "        return loss\n",
        "\n",
        "    def extract_features(self, inputs):\n",
        "        \"\"\"Extract style and content features\"\"\"\n",
        "        inputs = inputs * 255.0\n",
        "        preprocessed_input = tf.keras.applications.vgg19.preprocess_input(inputs)\n",
        "        outputs = self.vgg(preprocessed_input)\n",
        "\n",
        "        style_outputs, content_outputs = (outputs[:self.num_style_layers],\n",
        "                                          outputs[self.num_style_layers:])\n",
        "\n",
        "        style_outputs = [self.gram_matrix(style_output) for style_output in style_outputs]\n",
        "\n",
        "        content_dict = {content_name: value\n",
        "                        for content_name, value in zip(self.content_layers, content_outputs)}\n",
        "\n",
        "        style_dict = {style_name: value\n",
        "                      for style_name, value in zip(self.style_layers, style_outputs)}\n",
        "\n",
        "        return {'content': content_dict, 'style': style_dict}\n",
        "\n",
        "    def high_pass_x_y(self, image):\n",
        "        \"\"\"High pass filter for total variation loss\"\"\"\n",
        "        x_var = image[:, :, 1:, :] - image[:, :, :-1, :]\n",
        "        y_var = image[:, 1:, :, :] - image[:, :-1, :, :]\n",
        "        return x_var, y_var\n",
        "\n",
        "    def total_variation_loss(self, image):\n",
        "        \"\"\"Calculate total variation loss for smoothness\"\"\"\n",
        "        x_deltas, y_deltas = self.high_pass_x_y(image)\n",
        "        return tf.reduce_sum(tf.abs(x_deltas)) + tf.reduce_sum(tf.abs(y_deltas))\n",
        "\n",
        "    @tf.function()\n",
        "    def train_step(self, image, style_targets, content_targets, optimizer):\n",
        "        \"\"\"Single training step\"\"\"\n",
        "        with tf.GradientTape() as tape:\n",
        "            outputs = self.extract_features(image)\n",
        "            loss = self.style_content_loss(outputs, style_targets, content_targets)\n",
        "            loss += self.total_variation_weight * tf.nn.l2_loss(self.total_variation_loss(image))\n",
        "\n",
        "        grad = tape.gradient(loss, image)\n",
        "        optimizer.apply_gradients([(grad, image)])\n",
        "        image.assign(tf.clip_by_value(image, clip_value_min=0.0, clip_value_max=1.0))\n",
        "        return loss\n",
        "\n",
        "    def transfer_style(self, content_path, style_path, epochs=10, steps_per_epoch=100):\n",
        "        \"\"\"Main style transfer function\"\"\"\n",
        "        # Load and preprocess images\n",
        "        content_image = self.preprocess_image(content_path)\n",
        "        style_image = self.preprocess_image(style_path)\n",
        "\n",
        "        # Extract style and content targets\n",
        "        style_targets = self.extract_features(style_image)['style']\n",
        "        content_targets = self.extract_features(content_image)['content']\n",
        "\n",
        "        # Initialize generated image\n",
        "        image = tf.Variable(content_image)\n",
        "\n",
        "        # Optimizer\n",
        "        opt = tf.optimizers.Adam(learning_rate=0.02, beta_1=0.99, epsilon=1e-1)\n",
        "\n",
        "        # Training loop\n",
        "        for epoch in range(epochs):\n",
        "            for step in range(steps_per_epoch):\n",
        "                loss = self.train_step(image, style_targets, content_targets, opt)\n",
        "\n",
        "            if epoch % 2 == 0:\n",
        "                logger.info(f\"Epoch {epoch}, Loss: {loss:.4f}\")\n",
        "\n",
        "        return image.numpy()\n",
        "\n",
        "# Flask Web Application\n",
        "app = Flask(__name__)\n",
        "\n",
        "# HTML Template\n",
        "HTML_TEMPLATE = \"\"\"\n",
        "<!DOCTYPE html>\n",
        "<html>\n",
        "<head>\n",
        "    <title>Neural Style Transfer</title>\n",
        "    <style>\n",
        "        body { font-family: Arial, sans-serif; margin: 40px; background: #f5f5f5; }\n",
        "        .container { max-width: 800px; margin: 0 auto; background: white; padding: 30px; border-radius: 10px; }\n",
        "        h1 { color: #333; text-align: center; }\n",
        "        .upload-section { margin: 20px 0; padding: 20px; border: 2px dashed #ddd; border-radius: 5px; }\n",
        "        .result-section { margin: 20px 0; text-align: center; }\n",
        "        input[type=file] { margin: 10px 0; }\n",
        "        button { background: #007bff; color: white; padding: 10px 20px; border: none; border-radius: 5px; cursor: pointer; }\n",
        "        button:hover { background: #0056b3; }\n",
        "        .loading { display: none; text-align: center; }\n",
        "        img { max-width: 100%; height: auto; margin: 10px; border-radius: 5px; }\n",
        "    </style>\n",
        "</head>\n",
        "<body>\n",
        "    <div class=\"container\">\n",
        "        <h1>ðŸŽ¨ Neural Style Transfer</h1>\n",
        "\n",
        "        <div class=\"upload-section\">\n",
        "            <h3>Upload Content Image</h3>\n",
        "            <input type=\"file\" id=\"contentImage\" accept=\"image/*\">\n",
        "            <div id=\"contentPreview\"></div>\n",
        "        </div>\n",
        "\n",
        "        <div class=\"upload-section\">\n",
        "            <h3>Upload Style Image</h3>\n",
        "            <input type=\"file\" id=\"styleImage\" accept=\"image/*\">\n",
        "            <div id=\"stylePreview\"></div>\n",
        "        </div>\n",
        "\n",
        "        <button onclick=\"transferStyle()\">Generate Stylized Image</button>\n",
        "\n",
        "        <div class=\"loading\" id=\"loading\">\n",
        "            <h3>Processing... This may take a few minutes.</h3>\n",
        "            <div>ðŸŽ¨ Applying artistic style...</div>\n",
        "        </div>\n",
        "\n",
        "        <div class=\"result-section\" id=\"result\"></div>\n",
        "    </div>\n",
        "\n",
        "    <script>\n",
        "        function previewImage(input, previewId) {\n",
        "            const file = input.files[0];\n",
        "            if (file) {\n",
        "                const reader = new FileReader();\n",
        "                reader.onload = function(e) {\n",
        "                    document.getElementById(previewId).innerHTML =\n",
        "                        '<img src=\"' + e.target.result + '\" style=\"max-width: 300px;\">';\n",
        "                };\n",
        "                reader.readAsDataURL(file);\n",
        "            }\n",
        "        }\n",
        "\n",
        "        document.getElementById('contentImage').addEventListener('change', function() {\n",
        "            previewImage(this, 'contentPreview');\n",
        "        });\n",
        "\n",
        "        document.getElementById('styleImage').addEventListener('change', function() {\n",
        "            previewImage(this, 'stylePreview');\n",
        "        });\n",
        "\n",
        "        async function transferStyle() {\n",
        "            const contentFile = document.getElementById('contentImage').files[0];\n",
        "            const styleFile = document.getElementById('styleImage').files[0];\n",
        "\n",
        "            if (!contentFile || !styleFile) {\n",
        "                alert('Please upload both images!');\n",
        "                return;\n",
        "            }\n",
        "\n",
        "            const formData = new FormData();\n",
        "            formData.append('content', contentFile);\n",
        "            formData.append('style', styleFile);\n",
        "\n",
        "            document.getElementById('loading').style.display = 'block';\n",
        "            document.getElementById('result').innerHTML = '';\n",
        "\n",
        "            try {\n",
        "                const response = await fetch('/transfer', {\n",
        "                    method: 'POST',\n",
        "                    body: formData\n",
        "                });\n",
        "\n",
        "                const data = await response.json();\n",
        "\n",
        "                if (data.success) {\n",
        "                    document.getElementById('result').innerHTML =\n",
        "                        '<h3>Result:</h3><img src=\"data:image/png;base64,' + data.result + '\">';\n",
        "                } else {\n",
        "                    alert('Error: ' + data.error);\n",
        "                }\n",
        "            } catch (error) {\n",
        "                alert('Error processing images: ' + error.message);\n",
        "            }\n",
        "\n",
        "            document.getElementById('loading').style.display = 'none';\n",
        "        }\n",
        "    </script>\n",
        "</body>\n",
        "</html>\n",
        "\"\"\"\n",
        "\n",
        "@app.route('/')\n",
        "def index():\n",
        "    return render_template_string(HTML_TEMPLATE)\n",
        "\n",
        "@app.route('/transfer', methods=['POST'])\n",
        "def transfer_style():\n",
        "    try:\n",
        "        # Get uploaded files\n",
        "        content_file = request.files['content']\n",
        "        style_file = request.files['style']\n",
        "\n",
        "        # Save temporary files\n",
        "        content_path = 'temp_content.jpg'\n",
        "        style_path = 'temp_style.jpg'\n",
        "\n",
        "        content_file.save(content_path)\n",
        "        style_file.save(style_path)\n",
        "\n",
        "        # Initialize style transfer model\n",
        "        nst = NeuralStyleTransfer()\n",
        "\n",
        "        # Perform style transfer\n",
        "        result_image = nst.transfer_style(content_path, style_path, epochs=5, steps_per_epoch=50)\n",
        "\n",
        "        # Convert result to base64\n",
        "        result_image = nst.deprocess_image(result_image)\n",
        "        pil_image = Image.fromarray(result_image)\n",
        "\n",
        "        buffer = io.BytesIO()\n",
        "        pil_image.save(buffer, format='PNG')\n",
        "        img_str = base64.b64encode(buffer.getvalue()).decode()\n",
        "\n",
        "        # Clean up temporary files\n",
        "        os.remove(content_path)\n",
        "        os.remove(style_path)\n",
        "\n",
        "        return jsonify({'success': True, 'result': img_str})\n",
        "\n",
        "    except Exception as e:\n",
        "        logger.error(f\"Error in style transfer: {str(e)}\")\n",
        "        return jsonify({'success': False, 'error': str(e)})\n",
        "\n",
        "@app.route('/health')\n",
        "def health_check():\n",
        "    return jsonify({'status': 'healthy', 'model': 'neural_style_transfer'})\n",
        "\n",
        "if __name__ == '__main__':\n",
        "    # Ensure TensorFlow uses CPU for compatibility\n",
        "    tf.config.set_visible_devices([], 'GPU')\n",
        "\n",
        "    print(\"ðŸŽ¨ Neural Style Transfer Web App Starting...\")\n",
        "    print(\"ðŸ“± Access the app at: http://localhost:5000\")\n",
        "    print(\"ðŸ”§ API endpoint: http://localhost:5000/transfer\")\n",
        "\n",
        "    app.run(debug=True, host='0.0.0.0', port=5000)"
      ]
    }
  ]
}